\documentclass[11pt]{article}

%%%%%%%%%%%%%%%%%%%
% Page Layout
%%%%%%%%%%%%%%%%%%%

\setlength{\paperwidth}{8.5in} \setlength{\paperheight}{11in}
\setlength{\marginparwidth}{0in} \setlength{\marginparsep}{0in}
\setlength{\oddsidemargin}{0in} \setlength{\evensidemargin}{0in}
\setlength{\textwidth}{6.5in} \setlength{\topmargin}{-0.5in}
\setlength{\textheight}{9in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Include Packages and Style Files
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumerate}
\usepackage{xcolor}
\usepackage[useregional]{datetime2}
%\usepackage[pdftex]{graphicx,color}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Define theorem environments
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{question}[theorem]{Question}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem*{remark}{Remark}

%%%%%%%%%%%%%%%%%%%%%%
% Define new commands
%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\R}{\mathbb{R}}


\newcommand{\E}{\mathbb{E}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\1}[1]{\mathbf{1} \left \{ #1 \right \}}
\newcommand{\Range}{\operatorname{Range}}

%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Time Series Analysis \\ Homework 3}
\date{Due: Wednesday, February 17th}
\author{Magon Bowling}

\maketitle

\begin{itemize}
    \item [{\color{red} \textbf{Problem 9}}] Let $\epsilon_i$ be a sequence of random variables with $E\epsilon_i = 0$, $E\epsilon_i^2 = \sigma^2$ if $i \neq j$.  Let $x_0 = 0$ and $|\rho| > 1$.  The sequence $x_k$ defined by
    \[x_i = \rho x_{i-1} + \epsilon_i, \ i = 1,2,....\]
    Compute $Ex_k$ and $Ex_k x_{k+2}$.
\end{itemize}
We start computing the elements of the recursion
\begin{equation*}
    \begin{split}
        x_1 &= \rho x_0 + \epsilon_1 \\
        x_2 &= \rho x_1 + \epsilon_2 = \rho(\rho x_0 + \epsilon_1) + \epsilon_2 = \rho^2 x_0 + \rho \epsilon_1 + \epsilon_2 \\
        x_3 &= \rho x_2 + \epsilon_3 = \rho(\rho^2 x_0 + \rho \epsilon_1 + \epsilon_2) + \epsilon_3 = \rho^3 x_0 + \rho^2 \epsilon_1 + \rho \epsilon_2 + \epsilon_3 \\
        \vdots \\
        x_k &= \rho^k x_0 + \sum_{\ell=0}^{\infty} \rho^{\ell} \epsilon_{k-\ell}
    \end{split}
\end{equation*}
If we let $x_0 = 0$ and $|\rho| > 1$ (an Explosive case) we write
\[\rho^{-k} x_k = x_0 + \rho^{-k} \sum_{\ell=0}^{k-1} \rho^{\ell} \epsilon_{k-\ell} = \sum_{\ell=0}^{k-1} \rho^{\ell-k} \epsilon_{k-\ell}.\]
We can perform an index shift with $j = k - \ell$,
\[\rho^{-k}x_k = \sum_{\ell=0}^{k-1} \rho^{-(k-\ell)} \epsilon_{k-\ell} = \sum_{j=1}^k \rho^{-j} \epsilon_j \Rightarrow x_k = \rho^k \sum_{j=1}^k \rho^{-j} \epsilon_j.\]
Now we compute $Ex_k$ to get
\[Ex_k = E\left[\rho^k \sum_{j=1}^k \rho^{-j} \epsilon_j\right] = \rho^k \sum_{j=1}^k \rho^{-j} E\epsilon_j = 0.\]
Similarly,
\begin{align*}
    Ex_k x_{k+2} &= E\left[\rho^k \sum_{\ell=0}^{k-1} \rho^{-j} \epsilon_j\right]\left[\rho^{k+2} \sum_{j=0}^{k+1} \rho^{-i} \epsilon_{i+2}\right] \\
    &= \rho^{2k+2} \sum_{\ell=0}^{k-1} \sum_{j=0}^{k+1} \rho^{-j-i} E(\epsilon_j \epsilon_{i+2})
\end{align*}
The errors are uncorrelated so $E\epsilon_j \epsilon_{i+2} = 0$ except when $j=i+2 \Rightarrow i=j-2$ when the expected value is $\sigma^2$.  Thus we get
\begin{align*}
    \rho^{2k+2} \sum_{\ell=0}^{k-1} \sum_{j=0}^{k+1} \rho^{-j-i} E(\epsilon_j \epsilon_{i+2}) &= \rho^{2k+2} \sum_{\ell=0}^{k-1} \rho^{-j}\rho^{-(j-2)} \sigma^2 \\
    &= \rho^{2k+2} \sigma^2 \sum_{\ell=0}^{k-1} \rho^{-2j+2} \\
    &= \rho^{2k+4} \sigma^2 \sum_{\ell=0}^{k-1} \rho^{-2j}
\end{align*}
Thus we get
\[Ex_k x_{k+2} = \rho^{2k+4} \left(\frac{\sigma^2}{1 - \rho^{-2}}\right).\]

\begin{itemize}
    \item [{\color{red} \textbf{Problem 10}}] Let $\epsilon_i, -\infty<i<\infty$, be independent and identically distributed random variables with $E\epsilon_i = 0$ and $E\epsilon_i^2 = \sigma^2$.  Let $x_i$ be the stationary solution of
    \[x_i = \frac{1}{3}x_{i-1} + \epsilon_i, \quad -\infty<i<\infty.\]
    If Var$(x_0) = 100$, determine $\sigma^2$.
\end{itemize}
We have $\phi = \frac{1}{3}$ thus
\[Z_i = x_i + \frac{1}{3}x_{i-1} + \frac{1}{9}x_{i-2} + ....\]
We know that
\begin{align*}
    E(Z_i) &= E\left(x_i + \frac{1}{3}x_{i-1} + \frac{1}{9}x_{i-2} + ... \right) \\
    &= 0
\end{align*}
so that $\{Z_i\}$ has a constant mean of zero.  Also,
\begin{align*}
    \text{Var}(Z_i) &= \text{Var}\left(x_i + \frac{1}{3}x_{i-1} + \frac{1}{9}x_{i-2} + ...\right) \\
    &=  \text{Var}(x_i) + \left(\frac{1}{3}\right)^2 \text{Var}(x_{i-1}) + \left(\frac{1}{3}\right)^4 \text{Var}(x_{i-2}) + ... \\
    &= \sigma_x^2 \left(1 + \frac{1}{9} + \frac{1}{81} + ...\right) \\
    &= \frac{\sigma_x^2}{1 - \frac{1}{9}}
\end{align*}
Therefore
\[\text{Var}(x_0) = 100 = \frac{\sigma_x^2}{1 - \frac{1}{9}} \Rightarrow \sigma_x^2 = \frac{800}{9}.\]

\end{document}
